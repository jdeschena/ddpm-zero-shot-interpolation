{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3f0e5ec2-68b0-416d-8124-0a99c3872b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_exp.data.attribute_celeba_dataset import Dataset, default_args\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "033f31c7-cc55-4209-83fd-cee62fb75963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split):\n",
    "    # Blond hair\n",
    "    args = OmegaConf.create(default_args())\n",
    "    args.target_attr = \"Blond_Hair\"\n",
    "    args.data_dir = \"../data\"\n",
    "    args.split = split\n",
    "    \n",
    "    blond_dataset = Dataset(**args)\n",
    "    blond_idxs = [idx for idx, (x,y) in enumerate(tqdm(blond_dataset)) if int(y) == 1]\n",
    "    print(\"Num blond:\", len(blond_idxs))\n",
    "\n",
    "    # Black hair\n",
    "    args = OmegaConf.create(default_args())\n",
    "    args.target_attr = \"Black_Hair\"\n",
    "    args.data_dir = \"../data\"\n",
    "    args.split = split\n",
    "    black_hair_dataset = Dataset(**args)\n",
    "    \n",
    "    black_hair_idxs = [idx for idx, (x, y) in enumerate(tqdm(black_hair_dataset)) if int(y) == 1]\n",
    "    print(\"Num black:\", len(black_hair_idxs))\n",
    "\n",
    "    both = set(blond_idxs).intersection(set(black_hair_idxs))\n",
    "\n",
    "    out = set()\n",
    "    out.update(blond_idxs)\n",
    "    out.update(black_hair_idxs)\n",
    "    out = out - both\n",
    "\n",
    "    out = list(out)\n",
    "    out.sort()\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8f43016c-4644-4514-8951-ff63018929ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = OmegaConf.create(default_args())\n",
    "args.target_attr = \"Blond_Hair\"\n",
    "args.data_dir = \"../data\"\n",
    "args.split = \"train\"\n",
    "blond_dataset = Dataset(**args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3a1fd45e-6437-470d-9e72-5c77a2a82c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 162770/162770 [00:04<00:00, 33667.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num blond: 24267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 162770/162770 [00:04<00:00, 33578.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num black: 38906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_set = get_dataset(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d88c8595-03ea-4007-8c51-4cb2dbbdfec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 19867/19867 [00:01<00:00, 10977.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num blond: 3056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 19867/19867 [00:00<00:00, 33607.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num black: 4144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_set = get_dataset(\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7b5ed2eb-e483-41fa-b635-55e5710e4136",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"blond_black_hair_train.txt\", \"w\") as f:\n",
    "    lines = [str(x) for x in train_set]\n",
    "    lines = \"\\n\".join(lines)\n",
    "    f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "050c02ab-6811-428a-97e8-57e7358b433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"blond_black_hair_valid.txt\", \"w\") as f:\n",
    "    lines = [str(x) for x in valid_set]\n",
    "    lines = \"\\n\".join(lines)\n",
    "    f.write(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbdb985-e2ae-4004-958d-9a840bae50ea",
   "metadata": {},
   "source": [
    "## Filter with eval classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6189d6ce-05bf-45bd-8c47-84ff0fa7bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import cv2\n",
    "import yaml\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from diff_exp.data.attribute_celeba_dataset import default_args, Dataset, _CELEBA_ATTRS\n",
    "from omegaconf import OmegaConf\n",
    "from diff_exp.transforms_utils import get_transform\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from diff_exp.utils import TransformDataset, tensor2pil\n",
    "from torchvision import transforms as tr\n",
    "import torch as th\n",
    "from einops import rearrange\n",
    "from tqdm import trange, tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import facer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60c41122-fa6b-4bf2-8890-ec90d7e4c00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_attr: Black_Hair\n",
      "data_dir: ../data\n",
      "split: train\n",
      "filter_path: blond_black_hair_train.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from diff_exp.data.attribute_celeba_dataset import default_args, Dataset, _CELEBA_ATTRS\n",
    "\n",
    "args = default_args()\n",
    "args = OmegaConf.create(args)\n",
    "# train\n",
    "args.data_dir = \"../data\"\n",
    "args.target_attr = \"Black_Hair\"\n",
    "args.filter_path = \"blond_black_hair_train.txt\"\n",
    "\n",
    "print(OmegaConf.to_yaml(args))\n",
    "dataset = Dataset(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edf9602f-f631-48df-9de9-caeb6dc5d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_attr: Black_Hair\n",
      "data_dir: ../data\n",
      "split: valid\n",
      "filter_path: blond_black_hair_valid.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from diff_exp.data.attribute_celeba_dataset import default_args, Dataset, _CELEBA_ATTRS\n",
    "\n",
    "args = default_args()\n",
    "args = OmegaConf.create(args)\n",
    "# valid\n",
    "args.data_dir = \"../data\"\n",
    "args.target_attr = \"Black_Hair\"\n",
    "args.filter_path = \"blond_black_hair_valid.txt\"\n",
    "args.split = \"valid\"\n",
    "\n",
    "print(OmegaConf.to_yaml(args))\n",
    "dataset = Dataset(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7d76dc79-d584-4461-a251-b1221a05602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_str = \"\"\"\n",
    "- - to_tensor\n",
    "- - center_crop\n",
    "  - size: 178\n",
    "- - resize\n",
    "  - size: 64\n",
    "- - normalize\n",
    "  - mean: 0.5, 0.5, 0.5\n",
    "  - std: 0.5, 0.5, 0.5\n",
    "\"\"\".strip()\n",
    "transform = yaml.load(transform_str, yaml.Loader)\n",
    "transform = OmegaConf.create(transform)\n",
    "transform = get_transform(transform)\n",
    "\n",
    "dataset = Dataset(**args)\n",
    "dataset = TransformDataset(dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "42f12884-d357-43c5-af00-e43f369d1005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'size': 's', 'num_classes': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calibrated_1.245.pt\n",
    "import torch as th\n",
    "from diff_exp.models.efficientnet import get_model, default_args\n",
    "import yaml\n",
    "from diff_exp.transforms_utils import get_transform\n",
    "from diff_exp.utils import TransformDataset\n",
    "\n",
    "model_args = default_args()\n",
    "model_args = OmegaConf.create(model_args)\n",
    "print(model_args)\n",
    "ckpt_path = \"/home/anon/artifacts/test_classifiers/blond_black_hair_64x64_cls_calibrated.pt\"\n",
    "model = get_model(model_args)\n",
    "ckpt = th.load(ckpt_path, map_location=\"cpu\")\n",
    "model.load_state_dict(ckpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "128dbb49-c00a-4358-a08c-3237dcdc18a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(\n",
    "    target_attr=\"Black_Hair\",\n",
    "    data_dir=\"../data\",\n",
    "    split=\"train\",\n",
    "    filter_path=\"/home/anon/Documents/DiffusionExtrapolation-code/diff_exp/data/blond_black_hair_extreme_ensemble/train.txt\"\n",
    ")\n",
    "transform_str = \"\"\"\n",
    "- - to_tensor\n",
    "- - center_crop\n",
    "  - size: 178\n",
    "- - resize\n",
    "  - size: 64\n",
    "- - normalize\n",
    "  - mean: 0.5, 0.5, 0.5\n",
    "  - std: 0.5, 0.5, 0.5\n",
    "\"\"\".strip()\n",
    "transform = yaml.safe_load(transform_str)\n",
    "transform = OmegaConf.create(transform)\n",
    "transform = get_transform(transform)\n",
    "\n",
    "dataset = TransformDataset(dataset, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39d200be-3940-4784-9127-a4b75368373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6954c48-189c-48a2-905c-7dfcc88a3544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 988/988 [00:07<00:00, 125.85it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "device = \"cuda:0\"\n",
    "\n",
    "loader = th.utils.data.DataLoader(dataset, pin_memory=True, batch_size=64, shuffle=False, drop_last=False, num_workers=10)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "for x, y in tqdm(loader):\n",
    "    x = x.to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(x).cpu()\n",
    "    all_preds.append(out)\n",
    "\n",
    "all_preds = th.cat(all_preds).softmax(-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b5aa82-d3f7-4f5d-aaf5-03de0834ca7f",
   "metadata": {},
   "source": [
    "## Send through farl for detecting attributes (unsuccessful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b951f5b8-a6b8-4df7-8798-37be0c322a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_exp.data.attribute_celeba_dataset import Dataset, default_args as data_args, _CELEBA_ATTRS\n",
    "from diff_exp.utils import mkdirs4file, TransformDataset\n",
    "from diff_exp.transforms_utils import get_transform\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "import os.path as osp\n",
    "from PIL import Image\n",
    "from diff_exp.models.efficientnet import default_args as model_args, get_model\n",
    "import torch as th\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import yaml\n",
    "from matplotlib import pyplot as plt\n",
    "import torchvision\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "import facer\n",
    "from einops import rearrange\n",
    "import torchvision.transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "039f8d65-5bc1-452f-8dd9-84c645a8acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attributes(loader, face_detector, face_attr):\n",
    "    # Age attribute\n",
    "    predicted_attributes = []\n",
    "    all_indices = []\n",
    "    all_labels = []\n",
    "    #    labels = face_attr.labels\n",
    "    idx_start = 0\n",
    "    for batch, y in tqdm(loader, desc=\"loading\"):\n",
    "        batch = batch.to(device)\n",
    "        indices = th.arange(idx_start, idx_start + len(batch))\n",
    "        idx_start += len(batch)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            faces = face_detector(batch)\n",
    "    \n",
    "        with torch.inference_mode():\n",
    "            faces = face_attr(batch, faces)\n",
    "    \n",
    "    \n",
    "        face_attrs = faces[\"attrs\"].cpu()\n",
    "        indices = indices[faces[\"image_ids\"].cpu()]\n",
    "        y = y[faces[\"image_ids\"].cpu()]\n",
    "        \n",
    "        predicted_attributes.append(face_attrs)\n",
    "        all_indices.append(indices)\n",
    "        all_labels.append(y)\n",
    "\n",
    "    predicted_attributes = th.cat(predicted_attributes)\n",
    "    all_indices = th.cat(all_indices)\n",
    "    all_labels = th.cat(all_labels)\n",
    "\n",
    "    return predicted_attributes, all_indices, all_labels\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "772b9b60-a512-4f44-9c7b-19d484f92418",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_args = data_args()\n",
    "ds_args = OmegaConf.create(ds_args)\n",
    "ds_args.data_dir = \"../data\"\n",
    "ds_args.filter_path = \"blond_black_hair_train.txt\"\n",
    "ds_args.target_attr = \"Black_Hair\"\n",
    "dataset = Dataset(**ds_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac1cfddf-784e-4f86-a163-d737e0b3aebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_blond_hair = sum(1 for x, y in dataset if int(y) == 0)\n",
    "n_black_hair = sum(1 for x, y in dataset if int(y) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "320cdc1d-e897-43d8-9517-6d1338c2a797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blond hair: 24265\n",
      "Black hair: 38904\n",
      "Ratio blond hair: 0.3841282907755386\n"
     ]
    }
   ],
   "source": [
    "print(\"Blond hair:\", n_blond_hair)\n",
    "print(\"Black hair:\", n_black_hair)\n",
    "print(\"Ratio blond hair:\", n_blond_hair / (n_blond_hair + n_black_hair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "556ba1a4-d5c6-4b6b-9361-4a7bf0ffed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(x):\n",
    "    x = np.array(x)\n",
    "    x = th.tensor(x)\n",
    "    x = rearrange(x, \"h w c -> c h w\")\n",
    "    return x\n",
    "\n",
    "transformed_dataset = TransformDataset(dataset, transform)\n",
    "len(dataset)\n",
    "loader = th.utils.data.DataLoader(transformed_dataset, batch_size=64, shuffle=False, drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1633ad2e-5238-4034-8697-5de71b5fa929",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:1\"\n",
    "face_detector = facer.face_detector(\"retinaface/mobilenet\", device=device)\n",
    "face_attr = facer.face_attr(\"farl/celeba/224\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a330e61-452f-4fb7-979a-256c85f66448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 988/988 [02:36<00:00,  6.30it/s]\n"
     ]
    }
   ],
   "source": [
    "celeba_attributes, celeba_indices, celeba_labels = get_attributes(loader, face_detector, face_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0d5da08d-4dbc-4470-abd5-11a7052da4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "young_idx = _CELEBA_ATTRS.index(\"Young\")\n",
    "smiling_idx = _CELEBA_ATTRS.index(\"Smiling\")\n",
    "bald_idx = _CELEBA_ATTRS.index(\"Bald\")\n",
    "blond_hair_idx = _CELEBA_ATTRS.index(\"Blond_Hair\")\n",
    "black_hair_idx = _CELEBA_ATTRS.index(\"Black_Hair\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83e1945d-5753-4614-b115-5a3f4555d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blond_idxs = []\n",
    "for idx, pred, label in zip(celeba_indices, celeba_attributes, celeba_labels):\n",
    "    if pred[blond_hair_idx].item() > 0.9 and label.item() == 0:\n",
    "        blond_idxs.append(int(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aec7d873-aaf8-4817-acfa-d6d1c091bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "black_hair_idxs = []\n",
    "for idx, pred, label in zip(celeba_indices, celeba_attributes, celeba_labels):\n",
    "    if pred[black_hair_idx].item() > 0.5 and label.item() == 1:\n",
    "        black_hair_idxs.append(int(idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3df45217-2b93-4779-a41e-bd95a2a5a716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blond hair (FaRL): 13049\n",
      "Black hair (FaRL): 1681\n"
     ]
    }
   ],
   "source": [
    "print(\"Blond hair (FaRL):\", len(blond_idxs))\n",
    "print(\"Black hair (FaRL):\", len(black_hair_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51328059-5681-4594-bd9d-f4e14f792d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1681"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(black_hair_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "78013870-3358-4005-86b3-083dc949a07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_black_idxs = [idx for idx in black_hair_idxs if celeba_attributes[idx][black_hair_idx].item() < 0.001 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "76e13533-1d06-493a-9590-9c2f97c7feb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_prob_blond_idxs = [idx for idx in blond_idxs if celeba_attributes[idx][blond_hair_idx].item() < 0.5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8572eba7-bf72-438e-9d64-7bf139bb7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_prob_black_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7e2b9a35-5eb2-43b4-98cb-b5502aa52b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8200"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(low_prob_blond_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "bd046c78-57a9-4124-af27-18ef4f1192be",
   "metadata": {},
   "outputs": [],
   "source": [
    "faulty_blond_idxs = list(range(8))\n",
    "faulty_black_hair_idxs = list(range(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "86d51f52-1318-473e-9cb6-880911ff1e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in faulty_black_hair_idxs:\n",
    "    idx = low_prob_black_idxs[idx]\n",
    "    img = dataset[idx][0]\n",
    "    save_path = f\"faulty_black_hair/{idx}.png\"\n",
    "    mkdirs4file(save_path)\n",
    "    img.save(save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f22cd4ee-8ea0-4ebe-832e-cdea4bd4fe83",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in faulty_blond_idxs:\n",
    "    idx = low_prob_blond_idxs[idx]\n",
    "    img = dataset[idx][0]\n",
    "    save_path = f\"faulty_blond_hair/{idx}.png\"\n",
    "    mkdirs4file(save_path)\n",
    "    img.save(save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbaf28-fd0c-44ce-aa08-609d0d4837a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(100):\n",
    "    _ = idx\n",
    "    idx = low_prob_black_idxs[idx]\n",
    "    img = dataset[idx][0]\n",
    "    display(dataset[idx][0])\n",
    "    print(celeba_attributes[idx][black_hair_idx].item())\n",
    "    print(_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fee8c4a-cea3-4bb4-89f2-a589b91e573c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
