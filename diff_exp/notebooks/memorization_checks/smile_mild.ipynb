{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "991e375f-5571-4ce8-8e96-4b76faf064ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88580fc8-4798-4a38-a901-047b80ad7d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diff_exp.scripts.faiss_find_closest import main as faiss_run, default_args as get_faiss_args\n",
    "from diff_exp.scripts.compute_embeddings import get_image_embeddings, default_args as get_embedding_args, load_model_and_processor, ProcessorDataset, DataLoader, mkdirs4file\n",
    "from diff_exp.data.npz_dataset import Dataset as NPZDataset\n",
    "from omegaconf import OmegaConf\n",
    "import torch as th\n",
    "th.set_grad_enabled(False)\n",
    "import numpy as np\n",
    "import yaml\n",
    "from diff_exp.utils import TransformDataset\n",
    "from diff_exp.transforms_utils import get_transform\n",
    "from tqdm import tqdm\n",
    "from einops import rearrange\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "998419c2-932d-4477-bdac-5cf93eb8e282",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_embeddings(args, dataset):\n",
    "    model, processor = load_model_and_processor(args.model_name)\n",
    "    #data = NPZDataset([args.input_npz])\n",
    "    dataset = ProcessorDataset(dataset, processor)\n",
    "    \n",
    "    loader = DataLoader(dataset, batch_size=args.batch_size, num_workers=args.num_workers, pin_memory=True)\n",
    "    model = model.to(args.device)\n",
    "    model.eval()\n",
    "    \n",
    "    all_embeddings = get_image_embeddings(args, model, processor, loader)\n",
    "    mkdirs4file(args.output_npz)\n",
    "    np.savez(args.output_npz, all_embeddings)\n",
    "    print(f\"Saved {len(all_embeddings)} embeddings to {args.output_npz}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a908ac37-efbe-407c-8584-9e634858f862",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_npz(dataset):\n",
    "    all_x = []\n",
    "    loader = DataLoader(dataset, batch_size=64, num_workers=12)\n",
    "    for x, y in tqdm(loader):\n",
    "        x = x * 255\n",
    "        x = x.byte()\n",
    "        x = x.numpy()\n",
    "        all_x.append(x)\n",
    "    all_x = np.concatenate(all_x)\n",
    "    all_x = rearrange(all_x, \"b c h w -> b h w c\")\n",
    "    return all_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1dbfb5-31b1-4552-9ea8-e96fe6e30440",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_samples_npz = \"/home/anon/samples/smile_size_ablation/60k/guid_30/samples_10000x64x64x3.npz\"\n",
    "generated_samples_embed_npz = \"embeddings/smile_mild/60k_guid_30.npz\"\n",
    "\n",
    "\n",
    "celeba_samples_npz = \"npz/celeba_train_60k.npz\"\n",
    "celeba_samples_embed_npz = \"embeddings/smile_mild/60k_guid_30_train.npz\"\n",
    "\n",
    "faiss_save_dir = \"smile_mild_plots\"\n",
    "\n",
    "filter_path = \"/home/anon/Documents/DiffusionExtrapolation-code/diff_exp/data/celeba_smile_train_size_ablation/60k.txt\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae62441-1c1a-479a-82c1-008498f55ab1",
   "metadata": {},
   "source": [
    "### Compute embeddings of generated samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "612df6bf-aafc-4fdc-b139-f68be961f8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_name: openai/clip-vit-base-patch32\n",
      "batch_size: 64\n",
      "device: cuda:1\n",
      "input_npz: /home/anon/samples/smile_size_ablation/60k/guid_30/samples_10000x64x64x3.npz\n",
      "output_npz: embeddings/smile_mild/60k_guid_30.npz\n",
      "num_workers: 10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding data...: 100%|████████████████████████████████████████████████████████████████████████████████████████| 157/157 [00:05<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10000 embeddings to embeddings/smile_mild/60k_guid_30.npz.\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset\n",
    "embed_args = get_embedding_args()\n",
    "embed_args = OmegaConf.create(embed_args)\n",
    "embed_args.batch_size = 64\n",
    "embed_args.device = \"cuda:1\"\n",
    "embed_args.input_npz = generated_samples_npz\n",
    "embed_args.output_npz = generated_samples_embed_npz\n",
    "embed_args.num_workers = 10\n",
    "\n",
    "print(OmegaConf.to_yaml(embed_args))\n",
    "\n",
    "# Embed dataaset\n",
    "dataset = NPZDataset(embed_args.input_npz)\n",
    "compute_embeddings(embed_args, dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1678a5d-4985-4176-a553-fe268c7e927e",
   "metadata": {},
   "source": [
    "### Compute embeddings of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6597be-5b91-4d6a-8d80-6ec79ed3ff47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset args:\n",
      "target_attr: Smiling\n",
      "data_dir: ../../data\n",
      "split: train\n",
      "filter_path: /home/anon/Documents/DiffusionExtrapolation-code/diff_exp/data/celeba_smile_train_size_ablation/60k.txt\n",
      "\n",
      "Dataset len: 60000\n",
      "-----\n",
      "Embedding args\n",
      "model_name: openai/clip-vit-base-patch32\n",
      "batch_size: 64\n",
      "device: cuda:1\n",
      "input_npz: /home/anon/samples/uncond_celeb_all_ddpm/samples_10000x64x64x3.npz\n",
      "output_npz: embeddings/smile_mild/60k_guid_30_train.npz\n",
      "num_workers: 10\n",
      "\n",
      "-----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding data...: 100%|████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:28<00:00, 32.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 60000 embeddings to embeddings/smile_mild/60k_guid_30_train.npz.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████| 938/938 [00:05<00:00, 183.45it/s]\n"
     ]
    }
   ],
   "source": [
    "from diff_exp.data.attribute_celeba_dataset import default_args as get_celeba_args, Dataset as CelebA\n",
    "\n",
    "# Prepare dataset\n",
    "celeba_args = get_celeba_args()\n",
    "celeba_args = OmegaConf.create(celeba_args)\n",
    "celeba_args.data_dir = \"../../data\"\n",
    "celeba_args.filter_path = filter_path\n",
    "\n",
    "celeba_dataset = CelebA(**celeba_args)\n",
    "print(\"Dataset args:\")\n",
    "print(OmegaConf.to_yaml(celeba_args))\n",
    "print(\"Dataset len:\", len(celeba_dataset))\n",
    "print(\"-----\")\n",
    "\n",
    "# Embed dataset\n",
    "embed_args = get_embedding_args()\n",
    "embed_args = OmegaConf.create(embed_args)\n",
    "embed_args.batch_size = 64\n",
    "embed_args.device = \"cuda:1\"\n",
    "embed_args.output_npz = celeba_samples_embed_npz\n",
    "embed_args.num_workers = 10\n",
    "print(\"Embedding args\")\n",
    "print(OmegaConf.to_yaml(embed_args))\n",
    "print(\"-----\")\n",
    "\n",
    "compute_embeddings(embed_args, celeba_dataset)\n",
    "\n",
    "# Make CelebA into npz (for faiss)\n",
    "transform_str = \"\"\"\n",
    "- - to_tensor\n",
    "- - center_crop\n",
    "  - size: 178\n",
    "- - resize\n",
    "  - size: 64\n",
    "\"\"\".strip()\n",
    "\n",
    "transform = yaml.safe_load(transform_str)\n",
    "transform = OmegaConf.create(transform)\n",
    "transform = get_transform(transform)\n",
    "\n",
    "transform = yaml.safe_load(transform_str)\n",
    "transform = get_transform(transform)\n",
    "celeba_transformed = TransformDataset(celeba_dataset, transform)\n",
    "celeba_npz = dataset_to_npz(celeba_transformed)\n",
    "\n",
    "mkdirs4file(celeba_samples_npz)\n",
    "np.savez(celeba_samples_npz, celeba_npz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6393c4-fbbc-457c-abde-072c730f213c",
   "metadata": {},
   "source": [
    "### Faiss + plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11e7a235-d9c5-4d82-8176-755b263daa51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_images: npz/celeba_train_60k.npz\n",
      "source_embeddings: embeddings/smile_mild/60k_guid_30_train.npz\n",
      "target_images: /home/anon/samples/smile_size_ablation/60k/guid_30/samples_10000x64x64x3.npz\n",
      "target_embeddings: embeddings/smile_mild/60k_guid_30.npz\n",
      "save_dir: smile_mild_plots\n",
      "use_cosine_sim: true\n",
      "top_k: 8\n",
      "n_images: 5\n",
      "dist_idx: 0\n",
      "suptitle: ''\n",
      "\n"
     ]
    }
   ],
   "source": [
    "faiss_args = get_faiss_args()\n",
    "faiss_args = OmegaConf.create(faiss_args)\n",
    "# Source: neighbouring images\n",
    "faiss_args.source_images = celeba_samples_npz\n",
    "faiss_args.source_embeddings = celeba_samples_embed_npz\n",
    "# Target: reference image\n",
    "faiss_args.target_images = generated_samples_npz\n",
    "faiss_args.target_embeddings = generated_samples_embed_npz\n",
    "faiss_args.save_dir = faiss_save_dir\n",
    "faiss_args.use_cosine_sim = True\n",
    "faiss_args.top_k = 8\n",
    "faiss_args.n_images = 5\n",
    "faiss_args.suptitle = \"\"\n",
    "print(OmegaConf.to_yaml(faiss_args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d630ca6a-619f-4913-85db-81e3795ad573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute top 8 neighbours in 0.95 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating neighbour images: 100%|███████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 17050.02it/s]\n"
     ]
    }
   ],
   "source": [
    "faiss_run(faiss_args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
