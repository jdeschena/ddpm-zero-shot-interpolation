data_dir: datasets/smile_ablation_10k
use_wandb_logger: true
wandb_project: celeba_diffusion_smile_size_ablation
schedule_sampler: uniform
lr: 0.0001
weight_decay: 0.0
lr_anneal_steps: 0
batch_size: 32
microbatch: -1
ema_rate: '0.9999'
log_interval: 10
save_interval: 10000
resume_checkpoint: "/raid/users/anon/artifacts/smile_size_ablation/diffusion/10k/ema_0.9999_100000.pt" 
dtype: fp16
fp16_scale_growth: 0.001
max_n_steps: 250_000
compile_module: false
image_size: 64
num_channels: 128
num_res_blocks: 3
num_heads: 4
num_heads_upsample: -1
num_head_channels: -1
attention_resolutions: 16,8
channel_mult: ''
dropout: 0.0
class_cond: false
use_checkpoint: false
use_scale_shift_norm: true
resblock_updown: false
use_new_attention_order: false
learn_sigma: true
diffusion_steps: 4000
noise_schedule: cosine
timestep_respacing: ''
use_kl: false
predict_xstart: false
rescale_timesteps: false
rescale_learned_sigmas: false
seed: 0
cfg_from: null
cfg_save_path: null
